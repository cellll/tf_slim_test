{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from preprocessing import inception_preprocessing\n",
    "from nets import inception_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size, height, width, is_training=True):\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset, common_queue_capacity=32, common_queue_min=8)\n",
    "    image_raw, label = data_provider.get(['image','label'])\n",
    "    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n",
    "    \n",
    "    image_raw = tf.expand_dims(image_raw, 0)\n",
    "    image_raw = tf.image.resize_images(image_raw, [height, width])\n",
    "    image_raw = tf.squeeze(image_raw)\n",
    "    \n",
    "    images, images_raw, labels = tf.train.batch(\n",
    "        [image, image_raw, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=1,\n",
    "        capacity=2*batch_size)\n",
    "\n",
    "    return images, images_raw, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_dir, train_sample_size, split_name):\n",
    "    CLASS_NAMES=['t72','willys']\n",
    "    file_pattern = os.path.join(dataset_dir, 't72willys_%s_*.tfrecord' % split_name)\n",
    "    \n",
    "    ITEMS_TO_DESCRIPTIONS = {\n",
    "        'image' : 'images',\n",
    "        'label' : 'labels'\n",
    "    }\n",
    "    \n",
    "    keys_to_features = {\n",
    "        'image/encoded' : tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format' : tf.FixedLenFeature((), tf.string, default_value='png'),\n",
    "        'image/class/label' : tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "    \n",
    "    items_to_handlers = {\n",
    "        'image' : slim.tfexample_decoder.Image(),\n",
    "        'label' : slim.tfexample_decoder.Tensor('image/class/label'),\n",
    "    }\n",
    "    \n",
    "    labels_to_names = {}\n",
    "    \n",
    "    for i in range(0, len(CLASS_NAMES)):\n",
    "        labels_to_names[i] = CLASS_NAMES[i]\n",
    "        \n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    \n",
    "    return slim.dataset.Dataset(\n",
    "        data_sources=file_pattern,\n",
    "        reader = tf.TFRecordReader,\n",
    "        decoder = decoder,\n",
    "        num_samples = train_sample_size,\n",
    "        items_to_descriptions = ITEMS_TO_DESCRIPTIONS,\n",
    "        num_classes = len(CLASS_NAMES),\n",
    "        labels_to_names=labels_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_init_fn():\n",
    "    \"\"\"Returns a function run by the chief worker to warm-start the training.\"\"\"\n",
    "    checkpoint_exclude_scopes=[\"InceptionV3/Logits\", \"InceptionV3/AuxLogits\", \"InceptionV3/ConcatFC\"]\n",
    "    \n",
    "    exclusions = [scope.strip() for scope in checkpoint_exclude_scopes]\n",
    "    \n",
    "    variables_to_restore = []\n",
    "    variables_to_retrain = []\n",
    "    \n",
    "\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variables_to_restore.append(var)\n",
    "        else:\n",
    "            variables_to_retrain.append(var)\n",
    "    \n",
    "    with tf.gfile.Open('inceptionv3_restore_list.txt', 'w') as f:\n",
    "        for var in variables_to_restore:\n",
    "             f.write('%s ::RESTORED FROM CHECKPOINT\\n' % (var))\n",
    "        for var in variables_to_retrain:\n",
    "             f.write('%s ::SELECTED FOR RETRAINING\\n' % (var))\n",
    " \n",
    "    \n",
    "    return slim.assign_from_checkpoint_fn(\n",
    "      '/root/qq/slim_test/ckpt/inception_v3.ckpt', variables_to_restore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SAMPLES = 500\n",
    "INCEPTION_IMAGE_SIZE=299\n",
    "BATCH_SIZE=32\n",
    "NUMBER_OF_STEP=1500\n",
    "LEARNING_RATE=0.0001\n",
    "slim = tf.contrib.slim\n",
    "TRAINED_MODEL_DIR='/root/qq/slim_test/training/zxcv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    train_dataset = get_dataset('/root/qq/t72_willys', TRAIN_SAMPLES, 'train')\n",
    "    images, _, labels = load_batch(train_dataset, BATCH_SIZE, INCEPTION_IMAGE_SIZE, INCEPTION_IMAGE_SIZE)\n",
    "    \n",
    "    test_dataset = get_dataset('/root/qq/t72_willys', TRAIN_SAMPLES, 'validation')\n",
    "    images2, _2, labels2 = load_batch(test_dataset, BATCH_SIZE, INCEPTION_IMAGE_SIZE, INCEPTION_IMAGE_SIZE)\n",
    "    \n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        net, _ = inception_v3.inception_v3(images, num_classes=None, is_training=True)\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        net2, _2 = inception_v3.inception_v3(images2, num_classes=None, is_training=True)\n",
    "        \n",
    "        net = slim.dropout(net, keep_prob=0.8, scope='Dropout_1b')\n",
    "        net2 = slim.dropout(net2, keep_prob=0.8, scope='Dropout_1b_2')\n",
    "        _['PreLogits'] = net\n",
    "        _2['PreLogits'] = net2\n",
    "        \n",
    "    with tf.variable_scope('InceptionV3/ConcatFC', reuse=tf.AUTO_REUSE) as scope:\n",
    "        merged_net = tf.concat(axis=3, values=[net, net2], name='PreLogitsConcat')\n",
    "        logits = slim.conv2d(merged_net, 2, [1,1], activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        logits = tf.squeeze(logits, [1,2], name = 'SpatialSqueeze')\n",
    "    \n",
    "        one_hot_labels = slim.one_hot_encoding(labels, train_dataset.num_classes)\n",
    "        slim.losses.softmax_cross_entropy(logits, one_hot_labels)\n",
    "        total_loss = slim.losses.get_total_loss()\n",
    "    \n",
    "        tf.summary.scalar('losses/Total Loss', total_loss)\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate = LEARNING_RATE)\n",
    "        train_op = slim.learning.create_train_op(total_loss, optimizer)\n",
    "    \n",
    "        final_loss = slim.learning.train(\n",
    "            train_op,\n",
    "            logdir=TRAINED_MODEL_DIR,\n",
    "            init_fn=get_init_fn(),\n",
    "            number_of_steps=NUMBER_OF_STEP)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "BATCH_SIZE = 30\n",
    "TEST_SAMPLE_SIZE = 1000\n",
    "\n",
    "all_batch_stats = []\n",
    "\n",
    "def getProbsAsStr(probabilities):\n",
    "    CLASS_NAMES=['t72','willys']\n",
    "    probs_str = 'Probabilities: '\n",
    "    for label, prob in zip(CLASS_NAMES, probabilities):\n",
    "        probs_str += '%s: %.2f%% ' % (label, prob*100)\n",
    "    return probs_str\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    tf.logging.set_verbosity(tf.logging.INFO)\n",
    "    train_dataset = get_dataset('/root/qq/t72_willys', TRAIN_SAMPLES, 'train')\n",
    "    images, images_raw, labels = load_batch(\n",
    "        train_dataset, BATCH_SIZE, INCEPTION_IMAGE_SIZE, INCEPTION_IMAGE_SIZE)\n",
    "    \n",
    "    test_dataset = get_dataset('/root/qq/t72_willys', TRAIN_SAMPLES, 'validation')\n",
    "    images2, images_raw2, labels2 = load_batch(\n",
    "        test_dataset, BATCH_SIZE, INCEPTION_IMAGE_SIZE, INCEPTION_IMAGE_SIZE)\n",
    "    \n",
    "    with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "        net, _ = inception_v3.inception_v3(images, num_classes=None, is_training=True)\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        net2, _2 = inception_v3.inception_v3(images2, num_classes=None, is_training=True)\n",
    "        \n",
    "        net = slim.dropout(net, keep_prob=0.8, scope='Dropout_1b')\n",
    "        net2 = slim.dropout(net2, keep_prob=0.8, scope='Dropout_1b_2')\n",
    "        _['PreLogits'] = net\n",
    "        _2['PreLogits'] = net2\n",
    "        \n",
    "    with tf.variable_scope('InceptionV3/ConcatFC', reuse=tf.AUTO_REUSE) as scope:\n",
    "        merged_net = tf.concat(axis=3, values=[net, net2], name='PreLogitsConcat')\n",
    "        logits = slim.conv2d(merged_net, 2, [1,1], activation_fn=None, normalizer_fn=None, scope='Conv2d_1c_1x1')\n",
    "        logits = tf.squeeze(logits, [1,2], name = 'SpatialSqueeze')\n",
    "\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "    \n",
    "    checkpoint_path = tf.train.latest_checkpoint(TRAINED_MODEL_DIR)\n",
    "    init_fn = slim.assign_from_checkpoint_fn(checkpoint_path, slim.get_variables_to_restore())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        with slim.queues.QueueRunners(sess):\n",
    "            sess.run(tf.initialize_local_variables())\n",
    "            init_fn(sess)\n",
    "\n",
    "            all_accuracy = []\n",
    "\n",
    "            for i in range(int(TEST_SAMPLE_SIZE/BATCH_SIZE)):\n",
    "\n",
    "                np_probabilities, np_images_raw, np_labels = sess.run([probabilities, images_raw, labels])\n",
    "                \n",
    "                all_batch_stats.append((np_labels, np_probabilities))\n",
    "                \n",
    "                if i == 1 or i == 5: # show images \n",
    "                    for j in range(BATCH_SIZE): \n",
    "                        image = np_images_raw[j, :, :, :]\n",
    "                        true_label = np_labels[j]\n",
    "                        predicted_label = np.argmax(np_probabilities[j, :])\n",
    "                        predicted_name = test_dataset.labels_to_names[predicted_label]\n",
    "                        true_name = test_dataset.labels_to_names[true_label]\n",
    "                        plt.figure()\n",
    "                        plt.imshow(image.astype(np.uint8))\n",
    "                        plt.title('Ground Truth: [%s], Prediction [%s] '\n",
    "                                  % (true_name, predicted_name) + getProbsAsStr(np_probabilities[j, :]))\n",
    "                        plt.axis('off')\n",
    "                        plt.show()\n",
    "\n",
    "# Calculate accuracy over the whole test set\n",
    "all_batch_accuracy = []\n",
    "for labels, probs in all_batch_stats:\n",
    "    for label, prob in zip(labels, probs):\n",
    "            all_batch_accuracy.append(np.argmax(prob) == label)\n",
    "print('Overall accuracy', np.mean(all_batch_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
