{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "import tensorflow as tf\n",
    "from preprocessing import inception_preprocessing\n",
    "from nets import inception_v3\n",
    "from PIL import Image\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "\n",
    "slim = tf.contrib.slim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_batch(dataset, batch_size, height, width, is_training=True):\n",
    "    data_provider = slim.dataset_data_provider.DatasetDataProvider(dataset, common_queue_capacity=32, common_queue_min=8)\n",
    "    image_raw, label = data_provider.get(['image','label'])\n",
    "    image = inception_preprocessing.preprocess_image(image_raw, height, width, is_training=is_training)\n",
    "    \n",
    "    image_raw = tf.expand_dims(image_raw, 0)\n",
    "    image_raw = tf.image.resize_images(image_raw, [height, width])\n",
    "    image_raw = tf.squeeze(image_raw)\n",
    "    \n",
    "    images, images_raw, labels = tf.train.batch(\n",
    "        [image, image_raw, label],\n",
    "        batch_size=batch_size,\n",
    "        num_threads=1,\n",
    "        capacity=2*batch_size)\n",
    "\n",
    "    return images, images_raw, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(dataset_dir, train_sample_size, split_name):\n",
    "    CLASS_NAMES=['t72','willys']\n",
    "    file_pattern = os.path.join(dataset_dir, 't72willys_%s_*.tfrecord' % split_name)\n",
    "    \n",
    "    ITEMS_TO_DESCRIPTIONS = {\n",
    "        'image' : 'images',\n",
    "        'label' : 'labels'\n",
    "    }\n",
    "    \n",
    "    keys_to_features = {\n",
    "        'image/encoded' : tf.FixedLenFeature((), tf.string, default_value=''),\n",
    "        'image/format' : tf.FixedLenFeature((), tf.string, default_value='png'),\n",
    "        'image/class/label' : tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\n",
    "    }\n",
    "    \n",
    "    items_to_handlers = {\n",
    "        'image' : slim.tfexample_decoder.Image(),\n",
    "        'label' : slim.tfexample_decoder.Tensor('image/class/label'),\n",
    "    }\n",
    "    \n",
    "    labels_to_names = {}\n",
    "    \n",
    "    for i in range(0, len(CLASS_NAMES)):\n",
    "        labels_to_names[i] = CLASS_NAMES[i]\n",
    "        \n",
    "    decoder = slim.tfexample_decoder.TFExampleDecoder(keys_to_features, items_to_handlers)\n",
    "    \n",
    "    return slim.dataset.Dataset(\n",
    "        data_sources=file_pattern,\n",
    "        reader = tf.TFRecordReader,\n",
    "        decoder = decoder,\n",
    "        num_samples = train_sample_size,\n",
    "        items_to_descriptions = ITEMS_TO_DESCRIPTIONS,\n",
    "        num_classes = len(CLASS_NAMES),\n",
    "        labels_to_names=labels_to_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset('/root/qq/t72_willys', 100, 'train')\n",
    "images, images_raw, labels = load_batch(train_dataset, 100, 299, 299)\n",
    "with tf.Session() as sess:\n",
    "    try:\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "        im, im_raw, lab = sess.run([images, images_raw, labels])\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    except:\n",
    "        print (\"Unexpected error:\", sys.exc_info()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_with_random_selector(x, func, num_cases):\n",
    "  \"\"\"Computes func(x, sel), with sel sampled from [0...num_cases-1].\n",
    "  Args:\n",
    "    x: input Tensor.\n",
    "    func: Python function to apply.\n",
    "    num_cases: Python int32, number of cases to sample sel from.\n",
    "  Returns:\n",
    "    The result of func(x, sel), where func receives the value of the\n",
    "    selector as a python integer, but sel is sampled dynamically.\n",
    "  \"\"\"\n",
    "  sel = tf.random_uniform([], maxval=num_cases, dtype=tf.int32)\n",
    "  # Pass the real x only to one of the func calls.\n",
    "  return control_flow_ops.merge([\n",
    "      func(control_flow_ops.switch(x, tf.equal(sel, case))[1], case)\n",
    "      for case in range(num_cases)])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distort_color(image, color_ordering=3, fast_mode=True, scope=None):\n",
    "  \"\"\"Distort the color of a Tensor image.\n",
    "  Each color distortion is non-commutative and thus ordering of the color ops\n",
    "  matters. Ideally we would randomly permute the ordering of the color ops.\n",
    "  Rather then adding that level of complication, we select a distinct ordering\n",
    "  of color ops for each preprocessing thread.\n",
    "  Args:\n",
    "    image: 3-D Tensor containing single image in [0, 1].\n",
    "    color_ordering: Python int, a type of distortion (valid values: 0-3).\n",
    "    fast_mode: Avoids slower ops (random_hue and random_contrast)\n",
    "    scope: Optional scope for name_scope.\n",
    "  Returns:\n",
    "    3-D Tensor color-distorted image on range [0, 1]\n",
    "  Raises:\n",
    "    ValueError: if color_ordering not in [0, 3]\n",
    "  \"\"\"\n",
    "  with tf.name_scope(scope, 'distort_color', [image]):\n",
    "    if fast_mode:\n",
    "      if color_ordering == 0:\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "      else:\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "    else:\n",
    "      if color_ordering == 0:\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "      elif color_ordering == 1:\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "      elif color_ordering == 2:\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "      elif color_ordering == 3:\n",
    "        image = tf.image.random_hue(image, max_delta=0.2)\n",
    "        image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n",
    "        image = tf.image.random_brightness(image, max_delta=32. / 255.)\n",
    "      else:\n",
    "        raise ValueError('color_ordering must be in [0, 3]')\n",
    "\n",
    "    # The random_* ops do not necessarily clamp.\n",
    "    return tf.clip_by_value(image, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scope=None\n",
    "bbox = tf.constant([0.0, 0.0, 1.0, 1.0], dtype=tf.float32, shape=[1, 1, 4])\n",
    "image = im_raw[0]\n",
    "with tf.name_scope(scope, 'distort_image', [image, 299, 299, bbox]):\n",
    "    # bbox\n",
    "    image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0), bbox)\n",
    "    #distorted_image, distorted_bbox = distorted_bounding_box_crop(image, bbox)\n",
    "    # bbox crop\n",
    "    bbox_begin, bbox_size, distort_bbox = tf.image.sample_distorted_bounding_box(tf.shape(image),\n",
    "                                                                                 bounding_boxes = bbox,\n",
    "                                                                                 min_object_covered=0.1,\n",
    "                                                                                 aspect_ratio_range=(0.75, 1.33),\n",
    "                                                                                 area_range=(0.05 , 1.0),\n",
    "                                                                                 max_attempts=100,\n",
    "                                                                                 use_image_if_no_bounding_boxes=True)\n",
    "    cropped_image = tf.slice(image, bbox_begin, bbox_size)\n",
    "    cropped_image.set_shape([None, None, 3])\n",
    "    image_with_distorted_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0), distort_bbox)\n",
    "    num_resize_cases = 4\n",
    "    distorted_image = apply_with_random_selector(cropped_image,\n",
    "                                                lambda x, method : tf.image.resize_images(x, [299, 299], method),\n",
    "                                                num_cases = num_resize_cases)\n",
    "    distorted_image_with_flip = tf.image.random_flip_left_right(distorted_image)\n",
    "    '''\n",
    "    distorted_image_with_color = apply_with_random_selector(\n",
    "        distorted_image_with_flip,\n",
    "        lambda x, ordering: distort_color(x, ordering, False),\n",
    "        num_cases=4)\n",
    "    '''\n",
    "    \n",
    "    distorted_image_with_contrast = tf.image.random_contrast(distorted_image_with_flip, lower=0.5, upper=1.5)\n",
    "    distorted_image_with_hue = tf.image.random_hue(distorted_image_with_contrast, max_delta=0.2)\n",
    "    distorted_image_with_saturation = tf.image.random_saturation(distorted_image_with_hue, lower=0.5, upper=1.5)\n",
    "    distorted_image_with_brightness = tf.image.random_brightness(distorted_image_with_saturation, max_delta=32./255.)\n",
    "    distorted_image_with_subtract = tf.subtract(distorted_image_with_brightness, 0.5)\n",
    "    distorted_image_with_multiply = tf.multiply(distorted_image_with_subtract, 2.0)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (image.shape)\n",
    "print (image_with_box)\n",
    "print (bbox_begin)\n",
    "print (bbox_size)\n",
    "print (distort_bbox)\n",
    "print (distorted_image)\n",
    "print (distorted_image_with_flip)\n",
    "print (distorted_image_with_contrast)\n",
    "print (distorted_image_with_hue)\n",
    "print (distorted_image_with_saturation)\n",
    "print (distorted_image_with_brightness)\n",
    "print (distorted_image_with_subtract)\n",
    "print (distorted_image_with_multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    iwb = sess.run(image_with_box)\n",
    "    cropped_image = sess.run(cropped_image)\n",
    "    #distort_bbox = sess.run(distort_bbox)\n",
    "    image_with_distorted_box = sess.run(image_with_distorted_box)\n",
    "    distorted_image = sess.run(distorted_image)\n",
    "    distorted_image_with_flip = sess.run(distorted_image_with_flip)\n",
    "    distorted_image_with_contrast = sess.run(distorted_image_with_contrast)\n",
    "    distorted_image_with_hue = sess.run(distorted_image_with_hue)\n",
    "    distorted_image_with_saturation = sess.run(distorted_image_with_saturation)\n",
    "    distorted_image_with_brightness = sess.run(distorted_image_with_brightness)\n",
    "    distorted_image_with_subtract = sess.run(distorted_image_with_subtract)\n",
    "    distorted_image_with_multiply = sess.run(distorted_image_with_multiply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(image.astype('uint8'))\n",
    "a.set_title('original')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(iwb[0].astype('uint8'))\n",
    "a.set_title('Image with box')\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(cropped_image.astype('uint8'))\n",
    "a.set_title('Cropped with bbox')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(image_with_distorted_box[0].astype('uint8'))\n",
    "a.set_title('Image with distorted bbox')\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(distorted_image.astype('uint8'))\n",
    "a.set_title('Distorted with random selector')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(distorted_image_with_flip.astype('uint8'))\n",
    "a.set_title('Distorted image with flip')\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(distorted_image_with_contrast.astype('uint8'))\n",
    "a.set_title('Distorted image with contrast')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(distorted_image_with_hue.astype('uint8'))\n",
    "a.set_title('Distorted image with hue')\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(distorted_image_with_saturation.astype('uint8'))\n",
    "a.set_title('Distorted image with saturation')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(distorted_image_with_brightness.astype('uint8'))\n",
    "a.set_title('Distorted image with brightness')\n",
    "\n",
    "fig = plt.figure()\n",
    "a = fig.add_subplot(121)\n",
    "img_plot = plt.imshow(distorted_image_with_subtract.astype('uint8'))\n",
    "a.set_title('Distorted image with subtract')\n",
    "a = fig.add_subplot(122)\n",
    "img_plot = plt.imshow(distorted_image_with_multiply.astype('uint8'))\n",
    "a.set_title('Distorted image with multiply')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
